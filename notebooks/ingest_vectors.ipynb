{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system environment variables\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "file_path = \"heartstart RAG.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions for Use\n",
      "HeartStart Intrepid\n",
      "Monitor /D efibrillator\n",
      "867172 \n",
      " English\n",
      "\n",
      "{'source': 'heartstart RAG.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hrisi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index with name `chatbotqa-index` is created\n",
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "INDEX_NAME = \"chatbotqa-index\"\n",
    "USE_SERVERLESS = True\n",
    "spec = ServerlessSpec(cloud = 'aws', region = 'us-east-1')\n",
    "# Initialize a ServerlessSpec object for AWS with the specified region\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "# Check if the index already exists in the current PC (presumably a database or similar)\n",
    "if USE_SERVERLESS:\n",
    "    if INDEX_NAME in pc.list_indexes().names():\n",
    "        # If the index exists, print a message indicating its existence\n",
    "        print(f\"Index `{INDEX_NAME}` already exists\")\n",
    "        INDEX = pc.Index(INDEX_NAME)        \n",
    "        # Print detailed statistics about the existing index\n",
    "        print(INDEX.describe_index_stats())\n",
    "        \n",
    "    # If the index does not exist, proceed to create a new one\n",
    "    else:\n",
    "        # Create a new index with specific parameters        \n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=768,\n",
    "            metric=\"cosine\",\n",
    "            spec=spec\n",
    "        )\n",
    "        \n",
    "    # Wait for the index to be initialized before proceeding\n",
    "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "        # Sleep for 1 second to avoid overloading the system with requests\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Once the index is ready, print a confirmation message\n",
    "    print(f\"Index with name `{INDEX_NAME}` is created\")\n",
    "    \n",
    "    # Retrieve the newly created index object\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    \n",
    "    # Print detailed statistics about the newly created index\n",
    "    print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert into Pinecone Vector DB Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "        splits,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='sentence-transformers/all-mpnet-base-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreive context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "INDEX_NAME = \"chatbotqa-index\"\n",
    "docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = docsearch.as_retriever(search_kwargs={\"k\": 3})\n",
    "results = retriver.invoke(\"How to install the battery?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 32.0, 'source': 'heartstart RAG.pdf'}\n",
      "{'page': 32.0, 'source': 'heartstart RAG.pdf'}\n",
      "{'page': 4.0, 'source': 'heartstart RAG.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in results:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "import os\n",
    "# Define the repo ID and connect to Mixtral model on Huggingface\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "  repo_id=repo_id, \n",
    "  model_kwargs={\"temperature\": 0.8, \"top_k\": 50}, \n",
    "  huggingfacehub_api_token=os.getenv('HUGGING_FACE_API_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\" <s> [INST] You are an expert in operating and maintaining the Philips HeartStart Intrepid monitor/defibrillator\n",
    "Users will ask you questions about the device and how to maintain and operate it. \n",
    "Use following piece of context to answer the question and return only your response.\n",
    "Use only the context to answer, do not give references. Simply answer the question without editorial comments.\n",
    "If you don't know the answer, just say you don't know. \n",
    "Keep the answer within 2 sentences and concise.\n",
    "</s> [/INST]\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template, \n",
    "  input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hrisi\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How to install the battery?',\n",
       " 'result': \"\\nYou are an expert in operating and maintaining the Philips HeartStart Intrepid monitor/defibrillator\\nUsers will ask you questions about the device and how to maintain and operate it. \\nUse following piece of context to answer the question and return only your response. \\nIf you don't know the answer, just say you don't know. \\nKeep the answer within 2 sentences and concise.\\n\\n\\nContext: Battery and AC Power 2: Device Basics\\n 19\\n WARNING: Do not connect a LAN cable to the HeartStart Intrepid. The LAN port is for factory use only. \\nBattery and AC Power\\nThis section describes basics of power supply. See “Power” on page 31 for a detailed discussion. \\nInstalling the Battery\\n\\uf0a5 To install the lithium ion battery:\\n1 Align the battery in the battery compartment. Confirm the arrow on the Battery Tab is \\npositioned at the bottom, see Figure 18. \\n2 Push the battery into the battery compartment until the battery latch is locked into place.\\n NOTE: Lift the latch while pushing the battery into the battery compartment. Once the battery is in the \\ncompartment, let the battery latch down to secure the battery inside the compartment.\\nRemoving the Battery\\n\\uf0a5 To remove the HeartStart Intrepid lithium ion battery:\\n1 Push the Battery Latch up. \\n2 The battery will eject out of the compartment. If it does not, pull on the Battery Tab to \\ncompletely remove the battery.\\n\\n1 Push the Battery Latch up. \\n2 The battery will eject out of the compartment. If it does not, pull on the Battery Tab to \\ncompletely remove the battery.\\n\\uf046\\uf069\\uf067\\uf075\\uf072\\uf065\\uf031\\uf038 Installing the Battery\\nBattery Latch\\nBattery Tab\\n\\nInstalling the Battery     .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .   19\\nRemoving the Battery   .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .   19\\nBattery Fuel Gauge .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .   20\\nAC Power Cord Guard .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .   20\\nT est Plug and T est Load   .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .      .   20\\n\\n2: Device Basics Additional Features\\n24\\n\\uf046\\uf069\\uf067\\uf075\\uf072\\uf065\\uf032\\uf037 Step 4 \\n5 Unsnap the rear buckle and swing out the right side pouch. Install 2 screws through the plastic \\npaper guide and into the holes in the right side of the device. Re-snap the rear buckle. The \\nplastic guide must match the plastic on the right side of the pouch.\\n\\uf046\\uf069\\uf067\\uf075\\uf072\\uf065\\uf032\\uf038 Step 5\\n6 Open the left side pouch. Using a short screwdriver, screw a snap stud through the hole in the \\ninside wall of the pouch, into the hole in the left side of the device. Close the left side pouch. \\n\\uf046\\uf069\\uf067\\uf075\\uf072\\uf065\\uf032\\uf039 Step 6\\nQuestion: How to install the battery?\\nAnswer\\nTo install the battery, align it in the battery compartment with the arrow on the Battery Tab at the bottom and push it into the compartment until the battery latch locks it in place.\"}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "            llm, retriever=docsearch.as_retriever(), chain_type_kwargs={\"prompt\": prompt}\n",
    "        )\n",
    "rag_chain.invoke(\"How to install the battery?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
